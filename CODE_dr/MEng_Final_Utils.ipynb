{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "#Data Read\n",
    "import imageio as io\n",
    "import os\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Data Augmentation\n",
    "from scipy.ndimage import interpolation as ip\n",
    "\n",
    "# Image Resizing\n",
    "from skimage.transform import resize\n",
    "from skimage import img_as_ubyte\n",
    "\n",
    "# Histogram of Gradients\n",
    "from skimage.feature import hog\n",
    "\n",
    "# Local Binary Patterns\n",
    "from skimage.feature import local_binary_pattern as lbp\n",
    "from skimage import color\n",
    "from sklearn.preprocessing import normalize\n",
    "import itertools\n",
    "from numpy import linalg as la\n",
    "\n",
    "# Bag of Words using KMeans\n",
    "from sklearn.cluster import KMeans\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Classification and High Level Feature Generation\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential,Model\n",
    "from keras.layers import Input,Dense, Activation, Dropout\n",
    "from keras import regularizers, optimizers\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import roc_curve,auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_key(path):\n",
    "    return int(os.path.basename(path)[:-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_files(path):\n",
    "    files = []\n",
    "    files = glob(os.path.join(path,'*.jpg'))\n",
    "    files.sort(key=sort_key)\n",
    "    return files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_images(image_paths):\n",
    "    images = []\n",
    "    for path in image_paths:\n",
    "        image = io.imread(path)\n",
    "        images.append(image)\n",
    "    \n",
    "    return images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_labels(path,names):\n",
    "    labels_df = pd.read_excel(path,names=names)\n",
    "    labels = labels_df.get_values()\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_data(images, shift_factor, path, name): ##Image Translation in 8 directions\n",
    "    image_name = name\n",
    "    a = shift_factor\n",
    "    #b = shift_factor1\n",
    "    shifts = ([a,0,0], [0,a,0], [-a,0,0], [0,-a,0], [a,a,0], [-a,-a,0], [-a,a,0], [a,-a,0])\n",
    "             #[a,b,0], [b,a,0], [-a,-b,0], [-b,-a,0], [-a,b,0], [b,-a,0], [-b,a,0], [a,-b,0])\n",
    "    for image in images:\n",
    "        for shift in shifts:\n",
    "            image_translated = ip.shift(image,shift,mode='nearest')\n",
    "            io.imwrite(path+'/'+str(image_name)+'.jpg',image_translated)\n",
    "            image_name = image_name+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_augmented_labels(labels,num_shifts):\n",
    "    augmented_labels = []\n",
    "    num_labels = labels.shape[1]\n",
    "    for row in labels:\n",
    "        row = np.repeat(row,num_shifts)\n",
    "        row = row.reshape((num_labels,num_shifts))\n",
    "        row = row.transpose()\n",
    "        augmented_labels.append(row)\n",
    "        \n",
    "    augmented_labels = np.asarray(augmented_labels)\n",
    "    augmented_labels = augmented_labels.reshape((len(labels)*num_shifts,num_labels))\n",
    "    \n",
    "    return augmented_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kfold_validation(training_data, training_labels, n_splits=5):\n",
    "    kfold = KFold(n_splits=n_splits, shuffle=True, random_state=0)\n",
    "    return kfold.split(training_data,training_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_augmented_images_and_labels(augmented_data):\n",
    "    \n",
    "    augmented_data_list = list(itertools.chain.from_iterable(augmented_data))\n",
    "    \n",
    "    augmented_images = []\n",
    "    augmented_labels = []\n",
    "    for i in range(0,len(augmented_data_list)):\n",
    "        item = augmented_data_list[i]\n",
    "        if i%2 == 0:\n",
    "            augmented_images.append(item)\n",
    "        else:\n",
    "            augmented_labels.append(item)\n",
    "            \n",
    "    augmented_images = list(itertools.chain.from_iterable(augmented_images))\n",
    "    augmented_labels = list(itertools.chain.from_iterable(augmented_labels))\n",
    "    augmented_labels = np.asarray(augmented_labels)\n",
    "    \n",
    "    return augmented_images, augmented_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Resizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_images(images,resize_factor):\n",
    "    resized_images = []\n",
    "    \n",
    "    width = (images[0].shape[0])*resize_factor \n",
    "    height = (images[0].shape[1])*resize_factor\n",
    "    for image in images:\n",
    "        resized_image = resize(image, (width,height), mode='reflect', anti_aliasing=True)\n",
    "        resized_image = img_as_ubyte(resized_image)\n",
    "        resized_images.append(resized_image)\n",
    "     \n",
    "    return resized_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histogram of Oriented Gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hog_features(images, cell_size, orientations=9):\n",
    "    \n",
    "    hog_features = []\n",
    "    \n",
    "    for image in images:\n",
    "        fd = hog(image, orientations=orientations, pixels_per_cell=(cell_size,cell_size),\n",
    "                    cells_per_block=(2, 2), block_norm='L2', visualize=False, multichannel=True)\n",
    "        \n",
    "        hog_features.append(fd)\n",
    "        \n",
    "    hog_features = np.asarray(hog_features)\n",
    "    \n",
    "    return hog_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local Binary Patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lbp_features(images,cell_size,neighbours=8,radius=1):\n",
    "    \n",
    "    lbp_features = []\n",
    "    nbins = neighbours + 2\n",
    "    \n",
    "    for image in images:\n",
    "        image = color.rgb2gray(image)\n",
    "        image = lbp(image,neighbours,radius,method='uniform')\n",
    " \n",
    "        image_blocks = []\n",
    "        image_block_cols = np.hsplit(image,round(image.shape[1]/cell_size)) \n",
    "    \n",
    "        for col in image_block_cols: \n",
    "            blocks = np.vsplit(col,round(image.shape[0]/cell_size))\n",
    "            image_blocks.append(blocks)\n",
    "            \n",
    "        image_blocks = list(itertools.chain.from_iterable(image_blocks))\n",
    "        \n",
    "        lbp_block_histograms = []\n",
    "        for block in image_blocks:\n",
    "            hist = np.histogram(block, bins=np.arange(0,nbins+1), range=(0,nbins))[0]\n",
    "            hist = hist/(la.norm(hist))\n",
    "            lbp_block_histograms.append(hist)\n",
    "                \n",
    "        lbp_block_histograms = (np.asarray(lbp_block_histograms)).flatten()\n",
    "        lbp_features.append(lbp_block_histograms)\n",
    "        \n",
    "    lbp_features = np.asarray(lbp_features)\n",
    "        \n",
    "    return lbp_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag Of Words-RGB Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_bow(images):\n",
    "        \n",
    "    shape = (images[0].shape[0]*images[0].shape[1],images[0].shape[2])\n",
    "    bow = np.array(images)\n",
    "    bow = bow.reshape((len(images),shape[0],shape[1]))\n",
    "    bow = bow.reshape((bow.shape[0]*bow.shape[1],bow.shape[2]))\n",
    "    bow = np.unique(bow, axis=0)\n",
    "    bow = bow/255\n",
    "    return bow    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bow_features(images,k,kmeans):\n",
    "    \n",
    "    bow_features = []\n",
    "    shape = (images[0].shape[0]*images[0].shape[1],images[0].shape[2])\n",
    "    for image in images:\n",
    "        image = image.reshape((shape))\n",
    "        image = image/255\n",
    "        predictions = kmeans.predict(image)\n",
    "        pred_freq = collections.Counter(predictions)\n",
    "        histogram = []\n",
    "        for i in range(0,k):\n",
    "            value = pred_freq[i]\n",
    "            histogram.append(value)\n",
    "        \n",
    "        histogram = np.asarray(histogram)\n",
    "        histogram = histogram/(la.norm(histogram))\n",
    "        bow_features.append(histogram)\n",
    "        \n",
    "    bow_features = np.asarray(bow_features)\n",
    "    \n",
    "    return bow_features  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_bow1(images):\n",
    "    bow = []\n",
    "    for image in images:\n",
    "        image = image.reshape((image.shape[0]*image.shape[1],image.shape[2]))\n",
    "        image = np.unique(image, axis=0)\n",
    "        bow.append(image)\n",
    "        \n",
    "    bow = list(itertools.chain.from_iterable(bow))\n",
    "    bow = np.asarray(bow) \n",
    "    bow = bow/255\n",
    "    return bow    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## High Level Feature Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_relu(x):\n",
    "    return K.relu(x, alpha=0.0, max_value=1.0, threshold=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_autoencoder_model(input_size, hidden_size, hidden_activation='relu', output_activation='linear', dropout1=0.0, dropout2=0.0, regularizer=None):\n",
    "    \n",
    "    input_layer = Input(shape=(input_size,))\n",
    "    encoder_layer = Dropout(dropout1)(input_layer)\n",
    "    encoder_layer = Dense(hidden_size, activation=hidden_activation, activity_regularizer=regularizer)(encoder_layer)\n",
    "    decoder_layer = Dropout(dropout2)(encoder_layer)\n",
    "    decoder_layer = Dense(input_size, activation=output_activation)(decoder_layer)\n",
    "    autoencoder_model = Model(input_layer, decoder_layer)\n",
    "    encoder_model = Model(input_layer,encoder_layer)\n",
    "    \n",
    "    return autoencoder_model, encoder_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_deep_autoencoder_model(input_size, hidden_size, hidden_size1, hidden_activation='relu', output_activation='linear', dropout1=0.0, dropout2=0.0, dropout3=0.0, dropout4=0.0):\n",
    "    \n",
    "    input_layer = Input(shape=(input_size,))\n",
    "    encoder_layer = Dropout(dropout1)(input_layer)\n",
    "    encoder_layer = Dense(hidden_size1, activation=hidden_activation)(encoder_layer)\n",
    "    encoder_layer = Dropout(dropout2)(encoder_layer)\n",
    "    encoder_layer = Dense(hidden_size, activation=hidden_activation)(encoder_layer)\n",
    "    decoder_layer = Dropout(dropout3)(encoder_layer)\n",
    "    decoder_layer = Dense(hidden_size1, activation=hidden_activation)(decoder_layer)\n",
    "    decoder_layer = Dropout(dropout4)(decoder_layer)\n",
    "    decoder_layer = Dense(input_size, activation=output_activation)(decoder_layer)\n",
    "    autoencoder_model = Model(input_layer, decoder_layer)\n",
    "    encoder_model = Model(input_layer,encoder_layer)\n",
    "    \n",
    "    return autoencoder_model, encoder_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def autoencoder_compile_and_fit(model, train_data, num_epochs=100, lr=0.001, validation_split=0.15, validation_data=None, batch_size=None, callbacks=None):\n",
    "    \n",
    "    model.compile(optimizer=optimizers.Adam(lr=lr), loss='mse', metrics=['mse'])\n",
    "    history = model.fit(train_data, train_data, epochs=num_epochs, shuffle=True, validation_split=validation_split, validation_data=validation_data, batch_size=batch_size, verbose=0, callbacks=callbacks)\n",
    "    model_performance_vis(history,'MSE Loss','loss')\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_high_level_features(encoder_model,data):\n",
    "    \n",
    "    high_features_data = encoder_model.predict(data)\n",
    "    \n",
    "    return high_features_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_features(features):\n",
    "    normalized_features = []\n",
    "    for row in features:\n",
    "        min_value = row.min()\n",
    "        max_value = row.max()\n",
    "        row = (row-min_value)/(max_value-min_value)\n",
    "        normalized_features.append(row)\n",
    "    \n",
    "    normalized_features = np.asarray(normalized_features)\n",
    "    return normalized_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_LRL_model(input_size, output_size, dropout=0.0, regularizer=None):\n",
    "    \n",
    "    input_layer = Input(shape=(input_size,))\n",
    "    dropout_layer = Dropout(dropout)(input_layer)\n",
    "    output_layer = Dense(output_size, activation='sigmoid', kernel_regularizer=regularizer)(dropout_layer)\n",
    "    model = Model(input_layer,output_layer)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_and_fit(model, train_data, train_labels, num_epochs=100, lr=0.001, validation_split=0.15, validation_data=None, batch_size=None, callbacks=None):\n",
    "    \n",
    "    model.compile(optimizer=optimizers.Adam(lr=lr), loss='binary_crossentropy',metrics=['binary_crossentropy'])\n",
    "    history = model.fit(train_data, train_labels, epochs=num_epochs, shuffle=True, validation_split=validation_split, validation_data=validation_data, batch_size=batch_size, verbose=0, callbacks=callbacks)\n",
    "    model_performance_vis(history,'Crossentropy Loss','loss')\n",
    "    return history\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_probability_values(clf,test_data):\n",
    "    \n",
    "    predicted_probs = clf.predict_proba(test_data)\n",
    "    predicted_values = []\n",
    "    for arr in predicted_probs:\n",
    "        prob = arr[:,1]\n",
    "        predicted_values.append(prob)\n",
    "    \n",
    "    predicted_values = (np.asarray(predicted_values)).transpose()\n",
    "    \n",
    "    return predicted_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_and_threshold(model,test_data,test_labels):\n",
    "    \n",
    "    predicted_values = model.predict(test_data)\n",
    "    threshold_curve(test_labels,predicted_values)\n",
    "    threshold_curve1(test_labels,predicted_values)\n",
    "    \n",
    "    return predicted_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_performance_vis(history, metric_type, metric):\n",
    "    figure, ax= plt.subplots(1,1, figsize=(7,5))\n",
    "    ax.set_title('Train - Validation')\n",
    "    ax.plot(history.history[metric], 'r', label='Training '+metric)\n",
    "    ax.plot(history.history['val_'+metric], 'g' , ls='--', label='Validation '+metric)\n",
    "    ax.set_xlabel('epochs')\n",
    "    ax.set_ylabel(metric_type)\n",
    "    ax.legend(bbox_to_anchor=(1, 1), loc=1, borderaxespad=1)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_performance(history, history1, metric):\n",
    "    figure, ax= plt.subplots(1,1, figsize=(7,5))\n",
    "    ax.set_title('Train - Validation - Test')\n",
    "    ax.plot(history.history[metric], 'r', label='Training '+metric)\n",
    "    ax.plot(history.history['val_'+metric], 'g' , label='Validation '+metric)\n",
    "    ax.plot(history1.history['val_'+metric], 'b' , label='Test '+metric)\n",
    "    ax.set_xlabel('epochs')\n",
    "    ax.set_ylabel(metric)\n",
    "    ax.legend(bbox_to_anchor=(1, 1), loc=1, borderaxespad=1)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold_labels(predicted_values,threshold):\n",
    "    predicted_labels = np.array(predicted_values)\n",
    "    for index, x in np.ndenumerate(predicted_values):\n",
    "        if x < threshold:\n",
    "            predicted_labels[index] = 0\n",
    "        else:\n",
    "            predicted_labels[index] = 1\n",
    "    \n",
    "    return predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold_curve(true_labels,predicted_values):\n",
    "    \n",
    "    curve_values = []\n",
    "    thresholds = np.linspace(0,1.1,num=11,endpoint=False)\n",
    "    for threshold in thresholds:\n",
    "        labels = threshold_labels(predicted_values,threshold)\n",
    "        values = model_evaluation(true_labels,labels)[0]\n",
    "        curve_values.append(values)\n",
    "        \n",
    "    curve_values = np.asarray(curve_values)\n",
    "    \n",
    "    figure,ax = plt.subplots(1,1, figsize=(7,5))\n",
    "    ax.set_title('Threshold vs Performance')\n",
    "    ax.set_xlabel('Threshold')\n",
    "    ax.set_ylabel('Measure')\n",
    "    ax.plot(thresholds,curve_values[:,0], 'r', ls='--', label='Recall')\n",
    "    ax.plot(thresholds,curve_values[:,1], 'g', ls =':', label='Specificity')\n",
    "    ax.plot(thresholds,curve_values[:,2], 'b', label='Average')\n",
    "    #ax.plot(thresholds,curve_values[:,5], label='F-1')\n",
    "    ax.legend(bbox_to_anchor=(0.5,0), loc=8, borderaxespad=1)\n",
    "    plt.show()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold_curve1(true_labels,predicted_values):\n",
    "    \n",
    "    curve_values = []\n",
    "    thresholds = np.linspace(0,1.1,num=11,endpoint=False)\n",
    "    for threshold in thresholds:\n",
    "        labels = threshold_labels(predicted_values,threshold)\n",
    "        values = model_evaluation(true_labels,labels)[0]\n",
    "        curve_values.append(values)\n",
    "        \n",
    "    curve_values = np.asarray(curve_values)\n",
    "    \n",
    "    figure,ax = plt.subplots(1,1, figsize=(7,5))\n",
    "    ax.set_title('Threshold vs Performance')\n",
    "    ax.set_xlabel('Threshold')\n",
    "    ax.set_ylabel('Measure')\n",
    "    ax.plot(thresholds,curve_values[:,0], 'r', ls='--', label='Recall')\n",
    "    ax.plot(thresholds,curve_values[:,4], 'g', ls =':', label='Precision')\n",
    "    ax.plot(thresholds,curve_values[:,5], 'b', label='F1-score')\n",
    "    #ax.plot(thresholds,curve_values[:,5], label='F-1')\n",
    "    ax.legend(bbox_to_anchor=(0.5,0), loc=8, borderaxespad=1)\n",
    "    plt.show()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_avg(true_labels,predicted_values):\n",
    "    \n",
    "    curve_values = []\n",
    "    thresholds = np.linspace(0,1.1,num=11,endpoint=False)\n",
    "    for threshold in thresholds:\n",
    "        labels = threshold_labels(predicted_values,threshold)\n",
    "        values = model_evaluation(true_labels,labels)[0]\n",
    "        curve_values.append(values)\n",
    "        \n",
    "    curve_values = np.asarray(curve_values)\n",
    "    max_average = np.max(curve_values[:,2])\n",
    "    return max_average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_evaluation(test_labels,predicted_labels):\n",
    "    \n",
    "    #TP,FP,FN,TN\n",
    "    num_labels = test_labels.shape[1]\n",
    "    confusion_matrix = np.zeros((num_labels,4))\n",
    "    sum_labels = test_labels + predicted_labels\n",
    "    for i,row in enumerate(sum_labels):\n",
    "        for j,element in enumerate(row):\n",
    "            if element==2:\n",
    "                confusion_matrix[j,0]+=1\n",
    "            elif element==0:\n",
    "                confusion_matrix[j,3]+=1\n",
    "            elif element==1:\n",
    "                if test_labels[i,j]==1:\n",
    "                    confusion_matrix[j,2]+=1\n",
    "                else:\n",
    "                    confusion_matrix[j,1]+=1\n",
    "                    \n",
    "    evaluation_metrics = np.zeros((num_labels,6))\n",
    "    for i,row in enumerate(confusion_matrix):\n",
    "        recall = row[0]/(row[0] + row[2])\n",
    "        specificity = row[3]/(row[3] + row[1])\n",
    "        average = (recall + specificity)/2\n",
    "        accuracy = (row[0] + row[3])/(row[0] + row[1] + row[2] + row[3])\n",
    "        precision = row[0]/(row[0] + row[1])\n",
    "        f1_score = (2*precision*recall)/(precision+recall)\n",
    "        #f1_score = (2*row[0])/((2*row[0]) + row[1] + row[2])\n",
    "        \n",
    "        \n",
    "        evaluation_metrics[i,0] = recall\n",
    "        evaluation_metrics[i,1] = specificity\n",
    "        evaluation_metrics[i,2] = average\n",
    "        evaluation_metrics[i,3] = accuracy\n",
    "        evaluation_metrics[i,4] = precision\n",
    "        evaluation_metrics[i,5] = f1_score\n",
    "        \n",
    "        \n",
    "    avg = []\n",
    "    avg.append(np.nanmean(evaluation_metrics[:,0]))\n",
    "    avg.append(np.nanmean(evaluation_metrics[:,1]))\n",
    "    avg.append(np.nanmean(evaluation_metrics[:,2]))\n",
    "    avg.append(np.nanmean(evaluation_metrics[:,3]))\n",
    "    avg.append(np.nanmean(evaluation_metrics[:,4]))\n",
    "    avg.append(np.nanmean(evaluation_metrics[:,5]))\n",
    "    avg = np.asarray(avg)\n",
    "    \n",
    "     #sen, spec, avg\n",
    "        \n",
    "    return avg,confusion_matrix, evaluation_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_roc_curve(predicted_values, test_labels, avg_type='macro'):\n",
    "    \n",
    "    Y_test = test_labels\n",
    "    y_score = predicted_values\n",
    "    \n",
    "    n_classes = test_labels.shape[1]\n",
    "    \n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    for i in range(n_classes):\n",
    "        fpr[i], tpr[i], _ = roc_curve(Y_test[:, i], y_score[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "    # Compute micro-average ROC curve and ROC area\n",
    "    fpr[avg_type], tpr[avg_type], _ = roc_curve(Y_test.ravel(), y_score.ravel())\n",
    "    roc_auc[avg_type] = auc(fpr[avg_type], tpr[avg_type])\n",
    "\n",
    "    plt.figure(figsize=(7,5))\n",
    "    lw = 2\n",
    "    plt.plot(fpr[2], tpr[2], color='darkorange',\n",
    "         lw=lw, label='ROC curve (AUC = %0.4f)' % roc_auc[2])\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curve')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_precision_recall_curve(predicted_values, test_labels, avg_type='macro'):\n",
    "    \n",
    "    Y_test = test_labels\n",
    "    y_score = predicted_values\n",
    "    \n",
    "    n_classes = test_labels.shape[1]\n",
    "    \n",
    "    precision = dict()\n",
    "    recall = dict()\n",
    "    average_precision = dict()\n",
    "    for i in range(n_classes):\n",
    "        precision[i], recall[i], _ = precision_recall_curve(Y_test[:, i],\n",
    "                                                        y_score[:, i])\n",
    "        average_precision[i] = average_precision_score(Y_test[:, i], y_score[:, i])\n",
    "\n",
    "    # A \"micro-average\": quantifying score on all classes jointly\n",
    "    precision[avg_type], recall[avg_type], _ = precision_recall_curve(Y_test.ravel(), y_score.ravel())\n",
    "    \n",
    "    average_precision[avg_type] = average_precision_score(Y_test, y_score, average=avg_type)\n",
    "\n",
    "    area = auc(recall[avg_type], precision[avg_type])\n",
    "    \n",
    "    plt.figure(figsize=(7,5))\n",
    "    plt.step(recall[avg_type], precision[avg_type], color='b', alpha=0.2, where='post')\n",
    "    \n",
    "    plt.fill_between(recall[avg_type], precision[avg_type], alpha=0.2, color='b')\n",
    "\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.title('Precision-Recall Curve (AUC = %0.4f)' % area)\n",
    "    plt.show()\n",
    "    \n",
    "    return area"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
